{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from src.utils import clean_string\n",
    "from src.constants import PATH_DATA, PATH_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = f'{PATH_DATA}tweets.txt'\n",
    "model_revision = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367467d",
   "metadata": {},
   "source": [
    "# Этап 1. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bce70",
   "metadata": {},
   "source": [
    "##  1.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb23db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_file_path, \"r\", encoding=\"utf8\") as text_file:\n",
    "#     data_raw = text_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5165a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = pd.DataFrame(data_raw, columns=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw.to_csv(f'{PATH_DATA}raw_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a1fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = pd.read_csv(f'{PATH_DATA}raw_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fe0af",
   "metadata": {},
   "source": [
    "## 1.2 Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed = df_raw['tweet'].apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d9df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.read_csv(f'{PATH_DATA}dataset_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b426ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed.to_csv(f'{PATH_DATA}dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292aaa66",
   "metadata": {},
   "source": [
    "## 1.3 Разбиение на train / valid / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, valtest_texts = train_test_split(df_processed['tweet'][:50000].tolist(), test_size=0.2, random_state=random_state)\n",
    "val_texts, test_texts = train_test_split(valtest_texts, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_texts), len(val_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d648b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(df_processed) == len(X_train) + len(X_val) + len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fb44e",
   "metadata": {},
   "source": [
    "## 1.4 Создание объектов Dataset и Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.add_special_tokens({'bos_token': '[BOS]', 'eos_token': '[EOS]'})\n",
    "print(tokenizer.tokenize('ai can be misinterpreted as artificial intelligence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the vocabulary dictionary\n",
    "# vocab_dict = tokenizer.vocab\n",
    "# new_dict = {value:key for (key,value) in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс датасета\n",
    "class TextGenerationDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, input_seq_len):\n",
    "        self.samples = []\n",
    "        \n",
    "        for line in tqdm(texts):\n",
    "            line = ' '.join([tokenizer.bos_token, line, tokenizer.eos_token])\n",
    "            token_ids = tokenizer.encode(line, add_special_tokens=False, max_length=512, truncation=True)\n",
    "            if len(token_ids) == 1:\n",
    "                continue\n",
    "\n",
    "            for i in range(1, len(token_ids)):\n",
    "\n",
    "                if i >= input_seq_len:\n",
    "                    context = token_ids[i-input_seq_len:i] \n",
    "                else:\n",
    "                    context = [tokenizer.pad_token_type_id for _ in range(input_seq_len - i)] + token_ids[:i]\n",
    "\n",
    "                context += [tokenizer.mask_token_id]\n",
    "                \n",
    "                target = token_ids[i]\n",
    "                self.samples.append((context, target))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d614ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6827da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = FunnyDataset(val_texts, tokenizer, input_seq_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2598cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировочный и валидационный датасеты\n",
    "train_dataset = TextGenerationDataset(train_texts, tokenizer, input_seq_len=4)\n",
    "val_dataset = TextGenerationDataset(val_texts, tokenizer, input_seq_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98145b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# даталоадеры\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563620cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217f344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6af50f38",
   "metadata": {},
   "source": [
    "# Этап 2. Реализация рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=128,):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out, _ = self.rnn(emb)\n",
    "        hidden_state = out[:, -1, :]\n",
    "        linear_out = self.fc(hidden_state)\n",
    "        # print(f'FORWARD emb.shape = {emb.shape}')\n",
    "        # print(f'FORWARD out.shape = {out.shape}')\n",
    "        # print(f'FORWARD hidden_state.shape = {hidden_state.shape}')\n",
    "        # print(f'FORWARD linear_out.shape = {linear_out.shape}')\n",
    "\n",
    "        # raise ZeroDivisionError()\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d5440",
   "metadata": {},
   "source": [
    "## 2.1 Создание модели-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer)  \n",
    "hidden_dim = 128\n",
    "\n",
    "model = RnnTextGenerator(vocab_size, hidden_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d389ea6",
   "metadata": {},
   "source": [
    "# Этап 3. Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    sum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x_batch, y_batch) in enumerate(loader):\n",
    "            if i > 100:\n",
    "                break\n",
    "            x_output = model(x_batch)\n",
    "            loss = criterion(x_output, y_batch)\n",
    "            preds = torch.argmax(x_output, dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "            sum_loss += loss.item()\n",
    "    return sum_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c6279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddf5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa23526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл обучения\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for i, (x_batch, y_batch) in tqdm(enumerate(train_loader)):\n",
    "        # print(f'x_batch.shape = {x_batch.shape} / y_batch.shape = {y_batch.shape}')\n",
    "        if i > 1000:\n",
    "            break\n",
    "        optimizer.zero_grad()\n",
    "        x_output = model(x_batch)      \n",
    "        loss = criterion(model(x_batch), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # print(f'x_output = {x_output}')\n",
    "        # print(f'x_output.shape = {x_output.shape}')\n",
    "        # print(f'y_batch = {y_batch}')\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} | Val Accuracy: {val_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78582c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_revision += 1\n",
    "model_save_path = f'{PATH_MODEL}rnn_model_weights_rev{model_revision}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_loaded = RnnTextGenerator(vocab_size, hidden_dim)  # архитектура должна совпадать с сохранённой\n",
    "# model_loaded.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d8725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5abd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_generation_inference(\n",
    "        input_text, \n",
    "        model, \n",
    "        tokenizer, \n",
    "        input_seq_len=4\n",
    "    ):\n",
    "    # text preproc\n",
    "\n",
    "    line = ' '.join([tokenizer.bos_token, clean_string(input_text)])\n",
    "    token_ids = tokenizer.encode(line, add_special_tokens=False, max_length=512, truncation=True)\n",
    "\n",
    "    add_pads_cnt = input_seq_len - len(token_ids) \n",
    "    if add_pads_cnt > 0:\n",
    "        token_ids = [tokenizer.pad_token_type_id for _ in range(add_pads_cnt)] + token_ids\n",
    "\n",
    "    token_ids += [tokenizer.mask_token_id]\n",
    "\n",
    "    token_ids_tensor = torch.tensor(token_ids).unsqueeze(0)\n",
    "\n",
    "    logit = model(token_ids_tensor)\n",
    "    pred = torch.argmax(logit, dim=1)\n",
    "\n",
    "    pred_tok = tokenizer.convert_ids_to_tokens([pred.item()])[0]\n",
    "\n",
    "    # print(\n",
    "    #     f'line = {line}\\n'\n",
    "    #     f'token_ids = {token_ids}\\n'\n",
    "    #     f'token_ids_tensor = {token_ids_tensor}\\n'\n",
    "    #     f'logit = {logit}\\n'\n",
    "    #     f'pred = {pred}\\n'\n",
    "    #     f'pred_tok = {pred_tok}\\n'\n",
    "    # )\n",
    "    \n",
    "    return pred_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'My cat is not good'\n",
    "predo = word_generation_inference(\n",
    "    input_text,  model,  tokenizer\n",
    ")\n",
    "predo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa57c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c026874",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentense_generation_inference(\n",
    "        input_text, \n",
    "        model, \n",
    "        tokenizer,\n",
    "        min_input_seq_len=4,\n",
    "        max_total_length=128,\n",
    "    ):\n",
    "    # text preproc\n",
    "\n",
    "    generated_text = []\n",
    "    generated_word = ''\n",
    "\n",
    "    for i in tqdm(range(max_total_length)):\n",
    "        if max_total_length <= len(input_text) + len(generated_text):\n",
    "            print(f'BINGO')\n",
    "            break\n",
    "        print(f'generated_text = {generated_text}')\n",
    "        input_text = ' '.join([input_text, generated_word])\n",
    "        print(f'input_text = {input_text}')\n",
    "\n",
    "        generated_word = word_generation_inference(\n",
    "            input_text, \n",
    "            model, \n",
    "            tokenizer,\n",
    "            min_input_seq_len\n",
    "            )\n",
    "\n",
    "        if generated_word == tokenizer.eos_token:\n",
    "            print(f'ECHO EOS')\n",
    "            break\n",
    "\n",
    "        generated_text.append(generated_word)\n",
    "\n",
    "        # print(\n",
    "        #     f'pred = {pred}\\n'\n",
    "        #     f'pred_tok = {pred_tok}\\n'\n",
    "        # )\n",
    "        \n",
    "    return ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'My song know what you'\n",
    "sento = sentense_generation_inference(\n",
    "    input_text,  model,  tokenizer\n",
    ")\n",
    "sento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc3d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a86f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'My cat is not a good day'\n",
    "predo = word_generation_inference(\n",
    "    input_text, \n",
    "    model, \n",
    "    tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'My cat is not a good day'\n",
    "predo = word_generation_inference(\n",
    "    input_text, \n",
    "    model, \n",
    "    tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d54ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a36fc1",
   "metadata": {},
   "source": [
    "## 3.1 код замера и вывода метрики ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c597f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64706c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a89b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74183b6d",
   "metadata": {},
   "source": [
    "## 3.2 Код тренировки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9575fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508a6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa2b014e",
   "metadata": {},
   "source": [
    "## 3.3 Обучение модель, подобрав оптимальные параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c601441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e2f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2cb26e",
   "metadata": {},
   "source": [
    "# Этап 4. Использование предобученного трансформера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1700df0c",
   "metadata": {},
   "source": [
    "## 4.1 Воспользуйтесь моделью трансформера distilgpt2 из Transformers и дополните тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc72e63",
   "metadata": {},
   "source": [
    "## 4.2 код замера и вывода метрики ROUGE, но уже с использованием трансформера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba941fc",
   "metadata": {},
   "source": [
    "## 4.3 Подберите параметры генерации, замерьте качество модели на валидационной выборке, выведите примеры предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e8f24",
   "metadata": {},
   "source": [
    "# Этап 5. Формулирование выводов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959288d",
   "metadata": {},
   "source": [
    "## 5.1 Сравните примеры предсказаний двух моделей, а также получившиеся метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec0fdb",
   "metadata": {},
   "source": [
    "## 5.2 Сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77983b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7602f3e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
