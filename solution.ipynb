{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c48b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizerFast\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.utils import clean_string\n",
    "from src.constants import PATH_DATA, PATH_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = f'{PATH_DATA}tweets.txt'\n",
    "model_revision = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367467d",
   "metadata": {},
   "source": [
    "# Этап 1. Сбор и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32bce70",
   "metadata": {},
   "source": [
    "##  1.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb23db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file_path, \"r\", encoding=\"utf8\") as text_file:\n",
    "    data_raw = text_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5165a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(data_raw, columns=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fca0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw.to_csv(f'{PATH_DATA}raw_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a1fa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = pd.read_csv(f'{PATH_DATA}raw_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28fe0af",
   "metadata": {},
   "source": [
    "## 1.2 Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_raw['tweet'].apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b426ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed.to_csv(f'{PATH_DATA}dataset_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292aaa66",
   "metadata": {},
   "source": [
    "## 1.3 Разбиение на train / valid / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, valtest_texts = train_test_split(df_processed.tolist(), test_size=0.2, random_state=random_state)\n",
    "val_texts, test_texts = train_test_split(valtest_texts, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_texts), len(val_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d648b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(df_processed) == len(X_train) + len(X_val) + len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fb44e",
   "metadata": {},
   "source": [
    "## 1.4 Создание объектов Dataset и Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.add_special_tokens({'bos_token': '[BOS]', 'eos_token': '[EOS]'})\n",
    "print(tokenizer.tokenize('ai can be misinterpreted as artificial intelligence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access the vocabulary dictionary\n",
    "# vocab_dict = tokenizer.vocab\n",
    "# new_dict = {value:key for (key,value) in vocab_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# класс датасета\n",
    "class TextGenerationDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, input_seq_len=4):\n",
    "        self.samples = []\n",
    "        \n",
    "        for line in texts:\n",
    "            line = ' '.join([tokenizer.bos_token, line, tokenizer.eos_token])\n",
    "            token_ids = tokenizer.encode(line, add_special_tokens=False, max_length=512, truncation=True)\n",
    "            if len(token_ids) == 1:\n",
    "                continue\n",
    "\n",
    "            for i in range(1, len(token_ids)):\n",
    "\n",
    "                if i >= input_seq_len:\n",
    "                    context = token_ids[i-input_seq_len:i] \n",
    "                else:\n",
    "                    context = [tokenizer.pad_token_type_id for _ in range(input_seq_len - i)] + token_ids[:i]\n",
    "\n",
    "                context += [tokenizer.mask_token_id]\n",
    "                \n",
    "                target = token_ids[i]\n",
    "                self.samples.append((context, target))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d614ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d23312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generation_inference(input_text, model, tokenizer, input_seq_len=4):\n",
    "    # text preproc\n",
    "\n",
    "    line = ' '.join([tokenizer.bos_token, clean_string(input_text)])\n",
    "    token_ids = tokenizer.encode(line, add_special_tokens=False, max_length=512, truncation=True)\n",
    "\n",
    "    add_pads_cnt = input_seq_len - len(token_ids) \n",
    "    if add_pads_cnt > 0:\n",
    "        token_ids = [tokenizer.pad_token_type_id for _ in range(add_pads_cnt)] + token_ids\n",
    "\n",
    "    token_ids += [tokenizer.mask_token_id]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    token_ids_tensor = torch.tensor(token_ids).unsqueeze(0)\n",
    "\n",
    "    logit = model(token_ids_tensor)\n",
    "    pred = torch.argmax(logit, dim=1)\n",
    "\n",
    "    pred_tok = tokenizer.convert_ids_to_tokens([pred.item()])[0]\n",
    "\n",
    "    print(\n",
    "        f'line = {line}\\n'\n",
    "        f'token_ids = {token_ids}\\n'\n",
    "        f'token_ids_tensor = {token_ids_tensor}\\n'\n",
    "        f'logit = {logit}\\n'\n",
    "        f'pred = {pred}\\n'\n",
    "        f'pred_tok = {pred_tok}\\n'\n",
    "    )\n",
    "    \n",
    "    return pred_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b866a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Sorry seems to be at work'\n",
    "predo = text_generation_inference(\n",
    "    input_text, \n",
    "    model, \n",
    "    tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb75e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # класс датасета\n",
    "# class FunnyDataset(Dataset):\n",
    "#     def __init__(self, texts, tokenizer, input_seq_len=4):\n",
    "#         self.samples = []\n",
    "#         self.empty_token = tokenizer.pad_token_type_id\n",
    "\n",
    "#         for line in texts:\n",
    "#             line = tokenizer.bos_token + line + tokenizer.eos_token\n",
    "#             # token_ids = tokenizer.encode(line, add_special_tokens=False, max_length=512, truncation=True)\n",
    "#             token_ids = line.split() \n",
    "#             print(f'line = {line}')\n",
    "#             if len(token_ids) == 1:\n",
    "#                 continue\n",
    "\n",
    "#             for i in range(1, len(token_ids)):\n",
    "\n",
    "#                 if i >= input_seq_len:\n",
    "#                     context = token_ids[i-input_seq_len:i]\n",
    "#                 else: # i < input_seq_len\n",
    "#                     print(f'BINGO')\n",
    "#                     context = [self.empty_token for _ in range(input_seq_len - i)] + token_ids[:i]\n",
    "                \n",
    "#                 print(f'context = {context}')\n",
    "#                 target = token_ids[i]\n",
    "#                 self.samples.append((context, target))\n",
    "#             print(f'self.samples = {self.samples}')\n",
    "#             break\n",
    "           \n",
    "#     def __len__(self):\n",
    "#         return len(self.samples)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x, y = self.samples[idx]\n",
    "#         return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6827da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = FunnyDataset(val_texts, tokenizer, input_seq_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2598cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тренировочный и валидационный датасеты\n",
    "train_dataset = TextGenerationDataset(train_texts, tokenizer, input_seq_len=4)\n",
    "val_dataset = TextGenerationDataset(val_texts, tokenizer, input_seq_len=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98145b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# даталоадеры\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_loader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563620cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217f344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6af50f38",
   "metadata": {},
   "source": [
    "# Этап 2. Реализация рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnTextGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim=128, rnn_type=\"GRU\",):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "\n",
    "\n",
    "        rnn_cls = {\"RNN\": nn.RNN, \"GRU\": nn.GRU, \"LSTM\": nn.LSTM}[rnn_type]\n",
    "        self.rnn = rnn_cls(hidden_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        out, _ = self.rnn(emb)\n",
    "        # linear_out = self.fc(out)\n",
    "\n",
    "\n",
    "        # mask_position = x.size(1) # позиция центрального <MASK> токена\n",
    "        hidden_state = out[:, -1, :]\n",
    "\n",
    "        linear_out = self.fc(hidden_state)\n",
    "\n",
    "        # print(f'FORWARD emb.shape = {emb.shape}')\n",
    "        # print(f'FORWARD out.shape = {out.shape}')\n",
    "        # print(f'FORWARD hidden_state.shape = {hidden_state.shape}')\n",
    "        # print(f'FORWARD linear_out.shape = {linear_out.shape}')\n",
    "\n",
    "        # raise ZeroDivisionError()\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9dd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer)  \n",
    "hidden_dim = 128\n",
    "\n",
    "rnn_types = [\"RNN\", \"GRU\", \"LSTM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение\n",
    "print(f\"{'RNN Type':<8} | {'Params':>10}\")\n",
    "print(\"-\" * 35)\n",
    "for rnn_type in rnn_types:\n",
    "    model = RnnTextGenerator(vocab_size, hidden_dim, rnn_type,)\n",
    "    param_count = count_parameters(model)\n",
    "    print(f\"{rnn_type:<8} | {param_count:>10,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d5440",
   "metadata": {},
   "source": [
    "## 2.1 Создание модели-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RnnTextGenerator(vocab_size, rnn_type=\"LSTM\",)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d389ea6",
   "metadata": {},
   "source": [
    "# Этап 3. Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    sum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x_batch, y_batch) in enumerate(loader):\n",
    "            # if i > 50:\n",
    "            #     break\n",
    "            # x_batch, y_batch = x_batch, y_batch\n",
    "            x_output = model(x_batch)\n",
    "            loss = criterion(x_output, y_batch)\n",
    "            preds = torch.argmax(x_output, dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "            sum_loss += loss.item()\n",
    "    return sum_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c6279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ddf5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa23526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основной цикл обучения\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    for i, (x_batch, y_batch) in tqdm(enumerate(train_loader)):\n",
    "        # print(f'x_batch.shape = {x_batch.shape} / y_batch.shape = {y_batch.shape}')\n",
    "        if i > 1000:\n",
    "            break\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_output = model(x_batch)\n",
    "\n",
    "        # print(f'x_output = {x_output}')\n",
    "        # print(f'x_output.shape = {x_output.shape}')\n",
    "        # print(f'y_batch = {y_batch}')\n",
    "        \n",
    "        loss = criterion(model(x_batch), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} | Val Accuracy: {val_acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78582c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_revision += 1\n",
    "model_save_path = f'{PATH_MODEL}rnn_model_weights_rev{model_revision}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RnnTextGenerator(vocab_size, rnn_type=\"LSTM\",)  # архитектура должна совпадать с сохранённой\n",
    "model.load_state_dict(torch.load(model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcdec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689030e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_generation_inference(input_text, model, tokenizer, gen_max_length=50):\n",
    "    # text preproc\n",
    "    clean_text = clean_string(input_text)\n",
    "    # make inference in cicle\n",
    "\n",
    "    generated_text = []\n",
    "\n",
    "    for i in range(gen_max_length):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d8725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7a36fc1",
   "metadata": {},
   "source": [
    "## 3.1 код замера и вывода метрики ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64706c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a89b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74183b6d",
   "metadata": {},
   "source": [
    "## 3.2 Код тренировки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9575fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508a6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa2b014e",
   "metadata": {},
   "source": [
    "## 3.3 Обучение модель, подобрав оптимальные параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c601441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e2f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2cb26e",
   "metadata": {},
   "source": [
    "# Этап 4. Использование предобученного трансформера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1700df0c",
   "metadata": {},
   "source": [
    "## 4.1 Воспользуйтесь моделью трансформера distilgpt2 из Transformers и дополните тексты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc72e63",
   "metadata": {},
   "source": [
    "## 4.2 код замера и вывода метрики ROUGE, но уже с использованием трансформера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba941fc",
   "metadata": {},
   "source": [
    "## 4.3 Подберите параметры генерации, замерьте качество модели на валидационной выборке, выведите примеры предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e8f24",
   "metadata": {},
   "source": [
    "# Этап 5. Формулирование выводов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959288d",
   "metadata": {},
   "source": [
    "## 5.1 Сравните примеры предсказаний двух моделей, а также получившиеся метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ec0fdb",
   "metadata": {},
   "source": [
    "## 5.2 Сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77983b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7602f3e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
